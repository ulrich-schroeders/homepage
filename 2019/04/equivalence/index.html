<!DOCTYPE html>

<html lang="en">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="format-detection" content="telephone=no"/>

    <title>Testing for equivalence of test data across media | US</title>
    
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#FF3DB4">
    <meta name="theme-color" content="#ffffff">

    
    
    
    <link rel="stylesheet" href="https://ulrich-schroeders.de/css/main.min.975b1911c008aee6ab5fb42e51274b8268ebcb65dc15bd4a5f69b9eedb485c3e.css"/>

    
    
    

    
    
 
    </head>

    <body>
        
<nav style="overflow-y: hidden;">
  <header>
    <div class="site-title">
        <a href="/">US</a>
    </div>  
</header>

  <div class="nav-menu">
  
    <a class="color-link nav-link" href="/">Blog</a>
  
    <a class="color-link nav-link" href="/fixed/cv/">CV</a>
  
    <a class="color-link nav-link" href="/fixed/research/">Research</a>
  
    <a class="color-link nav-link" href="/fixed/best-practice/">Best practice</a>
  
    <a class="color-link nav-link" href="/fixed/publications/">Publications</a>
  
    <a class="color-link nav-link" href="/fixed/tests-questionnaires/">Tests/Questionnaires</a>
  
    <a class="color-link nav-link" href="/fixed/method-toolbox/">Method toolbox</a>
  
    <a class="color-link nav-link" href="/fixed/imprint/">Imprint</a>
  
  <a class="color-link nav-link" href="https://ulrich-schroeders.de/index.xml" target="_blank" rel="noopener" type="application/rss+xml">RSS</a>
</div>
<footer class="footer">
	<div class="social-icons">
        
    <a class="social-icon" href="mailto:schroeders@psychologie.uni-kassel.de" target="_blank" rel="noopener" title="Email">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
            <path d="M25.2794292,5.59128519 L14,16.8707144 L2.72057081,5.59128519 C3.06733103,5.30237414 3.51336915,5.12857603 4,5.12857603 L24,5.12857603 C24.4866308,5.12857603 24.932669,5.30237414 25.2794292,5.59128519 Z M25.9956978,6.99633695 C25.998551,7.04004843 26,7.08414302 26,7.12857603 L26,20.871424 C26,21.0798433 25.9681197,21.2808166 25.9089697,21.4697335 L18.7156355,14.2763993 L25.9956978,6.99633695 Z M24.9498374,22.6319215 C24.6672737,22.7846939 24.3437653,22.871424 24,22.871424 L4,22.871424 C3.5268522,22.871424 3.09207889,22.7071233 2.74962118,22.432463 L10.0950247,15.0870594 L13.9848068,18.9768415 L14.1878486,18.7737996 L14.2030419,18.7889929 L17.6549753,15.3370594 L24.9498374,22.6319215 Z M2.00810114,21.0526627 C2.00273908,20.9929669 2,20.9325153 2,20.871424 L2,7.12857603 C2,7.08414302 2.00144896,7.04004843 2.00430222,6.99633695 L9.03436454,14.0263993 L2.00810114,21.0526627 Z"></path>
        </svg>
    </a>
    

    

    
    <a class="social-icon" href="https://twitter.com/Navajoc0d3" target="_blank" rel="noopener" title="Twitter">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
            <path d="M8.991284,24.971612 C19.180436,24.971612 24.752372,16.530224 24.752372,9.210524 C24.752372,8.970656 24.747512,8.731868 24.736496,8.494376 C25.818008,7.712564 26.758256,6.737 27.5,5.62622 C26.507372,6.067076 25.439252,6.364292 24.318752,6.498212 C25.462472,5.812628 26.340512,4.727444 26.754584,3.434036 C25.684088,4.068536 24.499004,4.53002 23.23724,4.778528 C22.226468,3.701876 20.786828,3.028388 19.193828,3.028388 C16.134404,3.028388 13.653536,5.509256 13.653536,8.567492 C13.653536,9.0023 13.702244,9.424904 13.797176,9.830552 C9.19346,9.599108 5.11106,7.39472 2.3792,4.04294 C1.903028,4.861364 1.629032,5.812628 1.629032,6.827072 C1.629032,8.74904 2.606972,10.445612 4.094024,11.438132 C3.185528,11.41016 2.331788,11.160464 1.585184,10.745096 C1.583888,10.768208 1.583888,10.791428 1.583888,10.815728 C1.583888,13.49888 3.493652,15.738584 6.028088,16.246508 C5.562932,16.373084 5.07326,16.44134 4.56782,16.44134 C4.210988,16.44134 3.863876,16.406024 3.526484,16.34144 C4.231724,18.542264 6.276596,20.143796 8.701412,20.18894 C6.805148,21.674696 4.416836,22.56008 1.821488,22.56008 C1.374476,22.56008 0.93362,22.534592 0.5,22.4834 C2.951708,24.054476 5.862524,24.971612 8.991284,24.971612"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    
    

    
    
    

    

    
    <a class="social-icon" href="xnKlUWIAAAAJ" target="_blank" rel="noopener" title="Google Scholar">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
             <path d="M15.7399177,5.48151786 C15.149924,4.82272859 14.4663239,4.49480724 13.6933878,4.49480724 C12.8185607,4.49480724 12.1471312,4.80966127 11.6791845,5.43796013 C11.2112379,6.06433732 10.9771365,6.82326666 10.9771365,7.71483354 C10.9771365,8.47423262 11.1052474,9.24733956 11.3616402,10.035649 C11.6170934,10.8236168 12.0350768,11.5270314 12.6210136,12.1470458 C13.2049434,12.7685974 13.8844439,13.0787968 14.6564833,13.0787968 C15.5171327,13.0787968 16.189459,12.7903763 16.671626,12.2137916 C17.1517432,11.6379755 17.3927199,10.9111166 17.3927199,10.035649 C17.3927199,9.29000051 17.2655484,8.50924961 17.0102233,7.69296927 C16.7561365,6.87562134 16.3319184,6.13812924 15.739875,5.48156056 L15.7399177,5.48151786 Z M24.3072528,4.96950105 L24.3072528,13.3462071 C24.3072528,13.7339989 23.9898792,14.0515006 23.6019592,14.0515006 L23.3422783,14.0515006 C22.9543156,14.0515006 22.6369848,13.7341271 22.6369848,13.3462071 L22.6369848,4.96950105 C22.6369848,4.62513879 22.5869788,4.33765779 23.068249,4.27714671 L23.068249,3.16262405 L19.3634081,6.20120253 C19.4061972,6.28058863 19.446851,6.33132057 19.4854124,6.39789556 C19.8110278,6.97418137 19.9768461,7.69087679 19.9768461,8.56681414 C19.9768461,9.23824368 19.8649625,9.84134739 19.638078,10.3740328 C19.4122611,10.9065473 19.1375912,11.3415267 18.817143,11.6765369 C18.496652,12.0127855 18.1752643,12.3201237 17.8538766,12.5967152 C17.5324462,12.8739047 17.2577763,13.162923 17.0328135,13.4629589 C16.8060571,13.7620125 16.6932767,14.0712297 16.6932767,14.3917206 C16.6932767,14.7126813 16.8397076,15.0387237 17.1317151,15.3673283 C17.4226551,15.6968724 17.7805972,16.0162103 18.2038758,16.3317049 C18.6279231,16.6450216 19.0510736,16.9928002 19.4743522,17.3712399 C19.8985703,17.74921 20.2545052,18.2354765 20.5454452,18.8259399 C20.8385631,19.4186239 20.9848231,20.071093 20.9848231,20.7882582 C20.9848231,21.7343577 20.7435475,22.5887297 20.2626616,23.3491963 C19.7802812,24.1064175 19.1518542,24.7106315 18.3796867,25.1537246 C17.6054695,25.599807 16.777531,25.9355858 15.8945476,26.1623422 C15.0097279,26.3870488 14.1317408,26.5 13.2548639,26.5 C12.7014246,26.5 12.1429889,26.4573818 11.5814359,26.3697112 C11.0178757,26.2822114 10.4532907,26.1276668 9.8847343,25.9098782 C9.31502485,25.6906377 8.81052389,25.4214338 8.37319577,25.0981672 C7.93475736,24.778146 7.58181166,24.3652016 7.3111559,23.862238 C7.04054285,23.3591036 6.90615445,22.7936645 6.90615445,22.1655364 C6.90615445,21.4203577 7.1136515,20.7291563 7.52975591,20.0847582 C7.94586031,19.4451002 8.49707907,18.9108775 9.18272893,18.487727 C10.3789864,17.7434877 12.2558547,17.2836547 14.8102164,17.1098936 C14.2262867,16.3799173 13.9333396,15.6928582 13.9333396,15.0498693 C13.9333396,14.6841125 14.0289531,14.2920503 14.218173,13.8687717 C13.9130554,13.9113899 13.5987992,13.9355175 13.2781801,13.9355175 C11.9059836,13.9355175 10.7472627,13.4894351 9.80628769,12.5911638 C8.86535538,11.6944724 8.39535897,10.5719642 8.39535897,9.21488479 C8.39535897,9.07298054 8.39941581,8.94802965 8.40970739,8.8095417 L2.83316537,8.8095417 L11.2417283,1.5 L25.1668346,1.5 L23.87996,2.50451805 L23.87996,4.27748834 C24.3577712,4.3388962 24.3072955,4.62607827 24.3072955,4.96950105 L24.3072528,4.96950105 Z M15.8172967,17.9839947 C15.6566455,17.9549562 15.430914,17.9386434 15.1399313,17.9386434 C14.512273,17.9386434 13.8947782,17.9941154 13.2885571,18.1048887 C12.6822934,18.2126727 12.084186,18.3947184 11.4941496,18.6515809 C10.9019353,18.906906 10.423996,19.2823566 10.0597766,19.7787865 C9.69355004,20.274576 9.51150436,20.858463 9.51150436,21.5303623 C9.51150436,22.1706609 9.67215551,22.7419077 9.99371402,23.2394479 C10.3142049,23.7338281 10.7373127,24.1208513 11.2632509,24.3980408 C11.7891891,24.6756999 12.3405787,24.8854176 12.916224,25.0231795 C13.4929795,25.1600875 14.0799412,25.2311463 14.6780913,25.2311463 C15.8610679,25.2311463 16.8794647,24.9647609 17.7338794,24.4320756 C18.5863724,23.899561 19.0135798,23.0772595 19.0135798,21.9672634 C19.0135798,21.7338025 18.9810823,21.5040141 18.916856,21.2796064 C18.8498112,21.0527219 18.7835352,20.8585057 18.7185829,20.6972567 C18.6534171,20.5389543 18.529363,20.3483679 18.3462498,20.1286576 C18.1642041,19.9083067 18.0248194,19.7455631 17.9310848,19.6372239 C17.8354714,19.5253403 17.6565431,19.3656714 17.3929761,19.1545445 C17.131587,18.9425209 16.9647012,18.8103104 16.8904822,18.7614574 C16.8172027,18.7100422 16.6270434,18.5711699 16.3207728,18.3458227 C16.0147157,18.1186393 15.8468903,17.9981723 15.8173394,17.983952 L15.8172967,17.9839947 Z"></path>
        </svg>
    </a>
    

    

    
    <a class="social-icon" href="https://orcid.org/0000-0002-5225-1122" target="_blank" rel="noopener" title="Orcid">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
            <path d="M27,14 C27,21.1804687 21.1804687,27 14,27 C6.81953125,27 1,21.1804687 1,14 C1,6.81953125 6.81953125,1 14,1 C21.1804687,1 27,6.81953125 27,14 Z M9.76484375,19.9109375 L9.76484375,13.9492188 L9.76484375,9.03359375 L8.20078125,9.03359375 L8.20078125,19.9109375 L9.76484375,19.9109375 Z M12.0601563,9.03359375 L12.0601563,19.9210938 L16.3054688,19.9210938 C19.890625,19.9210938 22.0742188,17.2703125 22.0742188,14.4773437 C22.0742188,11.9078125 20.3070313,9.03359375 16.2851563,9.03359375 L12.0601563,9.03359375 Z M13.6242188,18.509375 L13.6242188,10.4453125 L16.03125,10.4453125 C19.078125,10.4453125 20.4695313,12.29375 20.4695313,14.4773437 C20.4695313,15.8179688 19.6570313,18.509375 16.1125,18.509375 L13.6242188,18.509375 Z M10.0085938,6.76875 C10.0085938,6.21015625 9.5515625,5.74296875 8.9828125,5.74296875 C8.4140625,5.74296875 7.95703125,6.2 7.95703125,6.76875 C7.95703125,7.32734375 8.4140625,7.79453125 8.9828125,7.79453125 C9.5515625,7.79453125 10.0085938,7.32734375 10.0085938,6.76875 Z"></path>
        </svg>
    </a>
    

    

</div>




	<p><a href="https://github.com/kimcc/hugo-theme-noteworthy" target="_blank" rel="noopener">Noteworthy theme</a></p>
	<p><a href="https://gohugo.io" target="_blank" rel="noopener">Built with Hugo</a></p>

	<script src="https://ulrich-schroeders.de/js/main.min.c1aee25a817e9beb1f9c4afd9d62311227a7f5e46720e404dc1dda97281f47f2.js" integrity="sha256-wa7iWoF+m+sfnEr9nWIxEien9eRnIOQE3B3alygfR/I=" crossorigin="anonymous"></script>
</footer>
</nav>

        <div id="content" class="content-container">
        

<h1 class="post-title">Testing for equivalence of test data across media</h1>
    
    <time>April 28, 2019</time>
    
    <div>
        <p>
        <p>
    <img class="article-image" src="/img/road.jpg" alt="" style="border-radius: 0px">
    


In 2009, I wrote a small chapter that was part of an EU conference book on the transition to computer-based assessment. Now and then I&rsquo;m coming back to this piece of work - in my teaching and my publications (e.g., the <a href="http://ulrich-schroeders.de/2010/10/smartphone-testing/">EJPA paper</a> on testing reasoning ability across different devices). Now I want to make it publically available. Hopefully, it will be interesting to some of you. The chapter is the (unaltered) preprint version of the book chapter, so if you want to cite it, please use the following citation:</p>
<p>Schroeders, U. (2009). Testing for equivalence of test data across media. In F. Scheuermann &amp; J. Björnsson (Eds.), <em>The transition to computer-based assessment. Lessons learned from the PISA 2006 computer-based assessment of science (CBAS) and implications for large scale testing</em> (pp. 164-170). JRC Scientific and Technical Report EUR 23679 EN.</p>
<h2 id="abstract">Abstract</h2>
<p>In order to stay abreast of social and technological changes and to capitalize on potential advantages of computer-based over paper-pencil testing, researchers are – in a first step of this transition process – concerned with moving already existing psychometric measures to computers. Therefore, testing for equivalence of a measure across test media becomes important in understanding whether computerizing measures affect the assessment of the underlying construct positively or adversely. In practical terms during the transition period equivalence is crucial in order to guarantee the comparability of test data and therewith the fairness for the test takers across media. After defining the term equivalence the available empirical evidence and proper statistical methods are discussed. It is argued that confirmatory factorial analysis is the soundest statistical tool for equivalence comparisons. The chapter concludes with some practical advices on what to do in order to adequately support the claim that a measure is equivalent across test media.</p>
<h2 id="introduction">Introduction</h2>
<p>Given the potential advantages of computer-based testing (CBT) over paper-pencil-testing (PPT) - like computer adaptive testing (CAT, see Thompson &amp; Weiss, this volume) or the potential to reduce costs of testing (see Latour, this volume) – educational and psychological testing is transferred considerably to a new test medium. Besides large scale studies (e.g., NAEP, see Bridgeman; CBAS, see Haldane, both this volume) there is a variety of small scale studies. In an initial step researchers are concerned to transfer readily available paper-based measures to computers. Subsequently, opportunities provided by the new test medium like multimedia extensions might catch a researcher’s interest and trigger additional changes of the instrument. These two trends reflect two different research strategies. This chapter addresses data analytic issues in the first research strategy, primarily, the issue of equivalence of measures across test media, and is divided into three sections: (A) <em>What is equivalence?</em>, (B) <em>Is there equivalence?</em>, and (C) <em>How to test for equivalence?</em> The chapter concludes with some practical recommendations on how to achieve equivalence.</p>
<h2 id="a-what-is-equivalence">(A) What is equivalence?</h2>
<p>Searching for the term equivalence in the &ldquo;Standards for educational and psychological testing&rdquo; (<a href="https://www.amazon.com/Standards-Educational-Psychological-Testing-1999/dp/0935302255">AERA, APA, &amp; NCME, 1999</a>) you will find several passages dealing with the issue. In the paragraphs about test administration (p. 62), score comparability (p. 57), and fairness of testing (p. 73) equivalence is immanent, but could easily be replaced by different labels like &ldquo;unbiasedness&rdquo; or &ldquo;test fairness&rdquo;. We will use the term &ldquo;equivalence&rdquo; following this working definition: The scores of measures are equivalent if they capture the same construct with the same measurement precision, providing interchangeable scores for individual persons. This definition suggests that two measures are equivalent if they are strict parallel, that is, test scores of such measures are solely dependent on the latent ability dimension and independent of test administration. Equivalence is given if the underlying source of all within group variance also accounts for the complete variance between the groups (PP vs. PC). Thus, equivalence is accurately described as measurement invariance (<a href="https://doi.org/10.1037//0021-9010.70.4.662">Drasgow &amp; Kanfer, 1985</a>). As we will see later on, there are different types of equivalence or measurement invariance. The next section will shed some light on the question whether evidence for equivalence can be found in the literature of educational and psychological testing.</p>
<h2 id="b-is-there-equivalence">(B) Is there equivalence?</h2>
<p>Numerous studies try to clarify the question of equivalence across test media with respect to a) a specific measure (e.g., the computerized GRE, <a href="https://doi.org/10.1177/0013164402238092">Goldberg &amp; Pedulla, 2002</a>), b) specific subgroups of testees (e.g., ethnic or gender groups, <a href="https://doi.org/10.1111/j.1745-3984.2002.tb01139.x">Gallagher, Bridgeman, &amp; Cahalan, 2002</a>) or c) specific soft- and hardware realizations (e.g., pen-based computer input, <a href="https://doi.org/10.1111/j.1744-6570.1996.tb01808.x">Overton, Taylor, Zickar, &amp; Harms, 1996</a>). However, the findings of these studies often remained unconnected and inconclusive. <a href="https://doi.org/10.1037/0033-2909.114.3.449">Mead and Drasgow (1993)</a> attempted to connect these individual findings in their frequently cited – but by now outdated – meta-analytical study. Their synopsis endorses the structural equivalence of ability test data for power tests gathered through CBT versus PPT. The cross-mode correlation corrected for measurement error was <em>r</em> = .97 whereas this coefficient was only <em>r</em> = .72 for speed tests. The authors argue that the reason for the low cross-mode correlation among speed tests is substantiated in different motor skill requirements and differences in presentation (instructions, presenting of the items). By adjusting the requirements of a CBT to a PPT both artifacts should be eliminated and equivalence should be established. Consistent with this suggestion, <a href="https://doi.org/10.1177/01466216980221006">Neuman and Baydoun (1998)</a> demonstrated that the differences across media can be minimized for clerical speed tests if CBT follows the same administration and response procedures as PPT. The authors concluded that their tests administered on different media measure the same construct but with different reliability.</p>
<p>Kim (1999) presented a comprehensive meta-analysis featuring two enhancements over Mead and Drasgow&rsquo;s earlier work: First, the sample of 51 studies including 226 effect sizes was more heterogeneous including studies on classroom tests and dissertations. Second, the authors corrected for within-study dependency in effect size estimation using a method recommended by <a href="https://www.amazon.com/Handbook-Research-Synthesis-Meta-Analysis/dp/0871540053">Gleser and Olkin (1994)</a>, thus, avoiding both the overrepresentation of studies with many dependent measures and the inflation of false positive outcomes. According to Kim, in a global evaluation of equivalence of computer-based vs. paper-based tests the most important distinction concerns CAT vs. CBT. For CAT, mathematics and sort of publication are significant moderators in predicting the effect size, however, considering CBT alone no significant moderators could be found.</p>
<p>In the recent past, two more meta-analyses (<a href="https://doi.org/10.1177/0013164406288166">Wang, Jiao, Young, Brooks, &amp; Olson, 2007</a>, <a href="https://doi.org/10.1177/0013164407305592">2008</a>) for mathematics and English reading comprehension respectively for K-12 students cover the research results of the last 25 years. For mathematics 14 studies containing 44 independent data sets allowed a comparison of the scores from PPT and CBT measures. After excluding six data sets contributing strongly to deviance in effect size homogeneity the weighted mean effect size was statistically not different from zero. One moderator variable, the delivery algorithm (fixed vs. adaptive) used in computerized administration, contributed statistically significant to the prediction of the effect size, whereas all other moderator variables investigated (study design, grade level, sample size, type of test, Internet-based testing, and computer practice) had no salient influence. For English reading assessment the weighted mean effect size was also not statistically different from zero after excluding six from 42 datasets extracted from eleven primary studies in an attempt to eliminate effect size heterogeneity. In comparison to the meta-analysis in mathematics, the moderator variables differ: Four moderator variables (study design, sample size, computer delivery algorithm, and computer practice) affected the differences in reading comprehension scores between test media and three other postulated moderator variables (grade level, type of test, and Internet-based testing) had no statistically meaningful influence. Even though, on a mean level no differences between test media could be found for mathematic and reading comprehension, the postulation of differential moderator variables for both disciplines might indicate a capitalization on chance or the relevance of unconsidered moderators (e.g., year of the study). Obviously the small sample of studies in both domains limits the generalizability of the results.</p>
<p>Considering all evidence presented so far, the effects of the test medium on test performance are nil or small. However, meta-analyses on the equivalence of ability measures across test media have a conceptual flaw. In order to allow an adequate assessment of the equivalence of test data across administration modes a comparison of mean scores (and dispersions) is insufficient. Let us explain this point in more detail.</p>
<p><a href="https://nces.ed.gov/nationsreportcard/pubs/studies/2005457.asp">Horkay, Bennett, Allen, and Kaplan (2005)</a> compared the performance of two nationally representative samples in a recent National Assessment of Educational Progress (NAEP) study in writing. One sample took the test on paper, the other sample worked on a computerized version. Albeit, means in both conditions were roughly the same, computer familiarity (consisting of a) hands-on computer proficiency, b) extent of computer use, and c) computer use for writing) added about 11% points over paper writing score to the prediction of writing performance in the PC-condition. Thus, students with greater hands-on skill achieved higher PC-writing scores when holding constant their performance on a paper-and-pencil writing test. Importantly, this difference in the construct measured by both instantiations would have remained undetected if the evaluation was solely based on tests of mean differences. So how does an appropriate procedure to test for equivalence between paper-based and computer-based measures look like?</p>
<h2 id="c-how-to-test-for-equivalence">(C) How to test for equivalence?</h2>
<p>Let us begin with the distinction between within- and between-subjects-designs in the context of cross-media-equivalence. Within the former the same subjects work both on paper and computer, within the latter different groups of subjects work either on paper or on computer. In both cases a potential test medium effect cannot be established by comparing or analyzing mean differences of the manifest or the latent scores. Strategies often applied in literature are based on the tacit assumption that the sources of within- and cross-media variance are actually the same. However, this assumption has to be tested by analyzing the means, variances and the covariances of the data. For the reflective measurement models used predominantly in educational and psychological measurement, the framework of confirmatory factor analysis (CFA) provides the best method for equivalence testing. In CFA the communality of many manifest variables is explained through a smaller number of underlying latent factors. This is achieved by, first, reproducing the covariance structure of the observed variables with the postulated covariance of a theoretical driven model, and second, evaluating the fit of the variable-reduced model to the empirical data. In case of a within-subject-design, the logic of testing is to check whether or not an additional, test medium specific factor accounts for unexplained variance and affects model fit beneficially. In case of a between-subject-design between-group comparisons and within-group comparisons are possible (for a detailed discussion see <a href="https://doi.org/10.1016/S0160-2896(03)00051-5">Lubke, Dolan, Kelderman, &amp; Mellenbergh, 2003</a>) by using multi-group confirmatory factor analysis (MGCFA).</p>
<p>Imagine the following within-subject-scenario: Subjects are tested on three different media (paper-pencil, notebook-computer, personal digital assistant (PDA)) with three reasoning tests covering the content domains verbal, numerical, and figural. The items might vary across media but could be considered as drawn from an item universe with equally constrained random selection. After completing the three tests on one medium subjects continue with the next medium. Ideally, the reasoning tests are parallel in difficulty and no learning effects occur between the tests. Sequence effects are controlled by having an additional between-groups factor in the design controlling for the six different sequences. As mentioned before, in order to test for equivalence in this example of a within-subject-design, first, a theoretical-based structural model has to be established. In our case this could be a model with three correlated content-specific-reasoning factors (verbal, numerical, figural) or a g-factor model (cp. <a href="https://doi.org/10.4135/9781452233529.n21">Wilhelm, 2005</a>). Through the introduction of a nested test medium factor one can try to tap construct-irrelevant variance in the covariance structure. Because the derived model with the nested medium-factor is nested within the original model (<a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118619179">Bollen, 1989</a>) the difference in model fit can be assessed with a conventional Chi-square-difference test.</p>

    <img class="article-image" src="/img/ctcm-1.png" alt="" style="border-radius: 0px">
    


<h3 id="figure-1-correlated-trait-correlated-method-minus-one-model-ctcm-1-model">Figure 1. Correlated-trait-correlated-method-minus-one-model (CTC(M-1)-model)</h3>
<p>In the multi-trait-multi-method-context different modeling strategies have been proposed to take method-specific variance – like the variance due to a test medium – into account. Figure 1 depicts a model with three traits and three methods – measured with nine indicators totally. Correlation within both traits and methods are allowed, but correlations between traits and methods are restricted to zero. Depending on theoretical considerations a number of competing models could be postulated, for instance, a correlated-trait-uncorrelated-method-model (CTUM-model, <a href="https://www.amazon.com/Handbook-Structural-Equation-Modeling-Hoyle/dp/1606230778">Marsh &amp; Grayson, 1995</a>). In case of inconsistent method artifacts on the indicators or an influence that is not unidimensional correlated errors should substitute method factors, resulting in two possible models: correlated-trait-correlated-uniqueness-model (CTCU-model) and the uncorrelated-trait-correlated-uniqueness-model (UTUC-model, <a href="https://doi.org/10.1177/014662168500900101">Widaman, 1985</a>). In order to solve identification problems with the CTCM model <a href="https://doi.org/10.1007/BF02294377">Eid (2000</a>; <a href="https://doi.org/10.1037/1082-989X.8.1.38">Eid, Lischetzke, Nussbeck &amp; Trierweiler, 2003</a>) proposed the correlated-trait-correlated-method-minus-one-model (CTC(M-1)-model). In this model one method is chosen as a reference that is excluded from modeling. This implies that the method factors have to be interpreted <em>in comparison</em> to the reference method. In our example it would probably be sensible to choose the paper-pencil-condition as a reference method because we want to establish whether computers make a difference in comparison to the traditional method of using paper-based measures. Both method factors are correlated and this correlation could be interpreted as a computer-literacy-method factor that is orthogonal to the other factors in this model. One advantage of the CTC(M-1)-model is that the variance is totally decomposed into a trait-specific, a method-specific, and an error component. One disadvantage of this model architecture might be that content and method factors are expected to be uncorrelated. Once method factors in the context of ability testing are interpreted it frequently turns out that those method factors might also express individual differences in methods and given the ubiquitous positive manifold amongst ability measures considering these method factors to be orthogonal to other ability factors is implausible. To sum up, in order to ascertain equivalence of data across media in the within-subject-model it is pivotal to check if the introduction of a method factor is required.</p>
<p>In the between-subject-design an extension of CFA – the multi-group confirmatory factor analysis (MGCFA) – is a suitable method to check for equivalence of test data gathered with different test media. If you look on the (overarching) CFA approach in terms of a regression model the prediction of the observed score y for a person j contingent on the latent ability level η through an indicator i on a medium m is described by Y(i,m,j) = τ(i,m) + λ(i,m) ∙ η(m,j) + ε(i,m,j), where τ is the intercept, λ is the factor loading and ε is the residual term. In order to guarantee measurement invariance all these variables have to be equal across test media conditions.</p>

    <img class="article-image" src="/img/measurement_invariance.png" alt="" style="border-radius: 0px">
    


<h3 id="figure-2-the-consequence-of-divergent-measurement-parameters-on-the-observed-score-note-that-there-is-a-perfect-overlap-between-the-ability-distributions-in-both-conditions">Figure 2. The consequence of divergent measurement parameters on the observed score. Note, that there is a perfect overlap between the ability distributions in both conditions.</h3>
<p>Consider another example of a paper-based test measuring crystallized intelligence. The test is transferred to computers and the researcher is confronted with the question of equivalence of the test across media. The three graphs in figure 2 describe various possible scenarios of measurement invariance for the crystallized intelligence test administered on both media, PP and PC. In the first graph (A) the subtests differ with regard to their slope or factor loadings (λ(i,PP) &gt; λ(i,PC)). In the second graph (B) the difference lies in the intercepts (τ(i,PP) &gt; τ(i,PC); the difference between the intercepts amount to the level of overprediction or underprediction. This situation of constant over- or underprediction independent of the ability level is referred to as uniform bias (<a href="https://doi.org/10.3102/10769986007002105">Mellenbergh, 1982</a>). In the third graph (C) the variance around the expected value is unequal implying different variances in the residual term (ε(i,PP) ≠ ε(i,PC)). Even though the underlying ability distribution in both groups is the same, unequal model parameters cause differences in the observed scores or, put differently, produce measurement invariance or non-equivalence. A straight forward procedure to assess the level of equivalence across test media is to compare four models in a fixed order, from the least to the most restrictive model.</p>
<h3 id="table-1-multi-group-confirmatory-factor-analysis-mgcfa-testing-for-equivalence-in-a-between-subject-design">Table 1. Multi-group confirmatory factor analysis (MGCFA): Testing for equivalence in a between-subject-design</h3>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>Continuous variables</strong></th>
<th style="text-align:center"><strong>Loadings</strong></th>
<th style="text-align:center"><strong>Intercepts</strong></th>
<th style="text-align:center"><strong>Residuals</strong></th>
<th style="text-align:center"><strong>Means</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Configural invariance</td>
<td style="text-align:center">*</td>
<td style="text-align:center">*</td>
<td style="text-align:center">*</td>
<td style="text-align:center">Fixed at 0</td>
</tr>
<tr>
<td style="text-align:left">Weak factorial invariance</td>
<td style="text-align:center">Fixed</td>
<td style="text-align:center">*</td>
<td style="text-align:center">*</td>
<td style="text-align:center">Fixed at 0</td>
</tr>
<tr>
<td style="text-align:left">Residual variance invariance</td>
<td style="text-align:center">Fixed</td>
<td style="text-align:center">*</td>
<td style="text-align:center">Fixed</td>
<td style="text-align:center">Fixed at 0</td>
</tr>
<tr>
<td style="text-align:left">Strict factorial invariance</td>
<td style="text-align:center">Fixed</td>
<td style="text-align:center">Fixed</td>
<td style="text-align:center">Fixed</td>
<td style="text-align:center">Fixed at 0/*</td>
</tr>
</tbody>
</table>
<p><em>Note</em>. The asterisk (*) indicates that the parameter is freely estimated. Fixed = the parameter is fixed to equity across groups; Fixed at 0 = factor means are fixed to 0 in both groups. Fixed at 0/* = factor means are fixed to 0 in the first group and freely estimated in all other groups.</p>
<p>Table 1 lists the different steps in invariance testing. In step 1, testing for configural invariance, all measurement parameters (factor loadings, residual variances, and intercepts) are freely estimated in both conditions (PP and PC). In step 2, metric invariance, models are invariant with respect to their factor loadings whereas all other parameters (residual variances and intercepts) are freely estimated. If measurement invariance is established on this stage, administration mode does not affect the rank order of individuals. This condition is also referred to as metric or weak invariance and is a prerequisite for meaningful cross-group comparisons (<a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118619179">Bollen, 1989</a>). In step 3, residual variance invariance, on top of the restrictions in step 2 the residual variances between groups are fixed to equality. In the most restrictive model (step 4) all measurement parameters are equal. If this standard is met strict factorial invariance (<a href="https://doi.org/10.1007/BF02294825">Meredith, 1993</a>) holds. <a href="https://pure.uva.nl/ws/files/4175964/46967_Wicherts.pdf">Wicherts (2007)</a> explains why – in the last step in testing for strict equivalence – it is essential to allow for differences in factor means while fixing the intercepts to equality. Neglecting this possibility would force any factor mean difference in the group into differences in the intercepts, thus, concealing group differences. Each of the above models is nested within the previous ones, for example, model C derives from model B by imposing additional constraints. Because of this nested character a potential deterioration in model fit is testable through a Chi-square-difference-test. <a href="https://doi.org/10.1207/S15328007SEM0902_5">Cheung and Rensvold</a> (2002) evaluated different goodness-of-fit indices with respect to a) their sensitivity to model misfit and b) dependency on model complexity and sample size. Based on a simulation they recommend using Δ(Gamma hat) and Δ(McDonald&rsquo;s noncentrality index) in addition to Δ(CFI) in order to evaluate measurement invariance. Although multi-group models are the method of choice in the between-subject scenario there are some interesting issues concerning: a) effect-sizes, b) location of invariance violation, c) application to ordinal measures, c) application to ordinal measures, and d) the modeling of non-invariance (<a href="https://www.amazon.com/Contemporary-Psychometrics-Multivariate-Applications-English-ebook/dp/B000SHOZXI">Millsap, 2005</a>).</p>
<h2 id="discussion">Discussion</h2>
<p>In this chapter two methods have been presented that have a series of advantages over non-factorial approaches and clearly are more adequate than procedures frequently applied in the literature. In this discussion we want to focus on some heuristics on what can be done to achieve equivalence prior to collecting data? Because the testing is influenced by both software (e.g., layout design) and hardware aspects (e.g., display resolution) much effort has been devoted to answer this question from a technological perspective, for example, about the legibility of online texts depending on font characteristics, length and number of lines, and white spacing (cp. <a href="https://doi.org/10.1207/s15327574ijt0601_1">Leeson, 2006</a>). Bearing in mind the rapid changes in soft- and hardware it seems hard to give long-lasting advice. Nevertheless, when you are testing on a variety of computers (e.g., using school facilities or testing unproctored via the Internet) try to implement a test environment that is independent of a specific operating system. In order to exclude as few candidates as possible keep the technical aspects of the testing simple. From a psychological perspective chances are enhanced to establish equivalence across test media if the PC-condition is handled and as thoroughly scrutinized as a parallel paper-based test form. However, even a sound construction does not immunize against violations of stronger forms of equivalence. In this case it is inevitable and advisable to account for the additional source of variance. One way to accomplish this is to survey potential moderators like computer experience, accessibility to computers, and hands-on skills. However, as long as we do not know exactly why essential properties of ability measures vary across test media, investigating the equivalence of computer- and paper-based test data is critical.</p>
<hr>
<h2 id="references">References</h2>
<ul>
<li>American Educational Research Association (AERA), American Psychological Association (APA), &amp; National Council on Measurement in Education (NCME). (1999). <em>Standards for educational and psychological testing.</em> Washington, DC: American Educational Research Association.</li>
<li>Bollen, K. A. (1989). <em>Structural equations with latent variables.</em> Oxford, England: John Wiley &amp; Sons. <a href="https://doi.org/10.1002/9781118619179">https://doi.org/10.1002/9781118619179</a></li>
<li>Cheung, G. W., &amp; Rensvold, R. B. (2002). Evaluating goodness-of-fit indexes for testing measurement invariance. <em>Structural Equation Modeling, 9</em>, 233–255. <a href="https://doi.org/10.1207/S15328007SEM0902_5">https://doi.org/10.1207/S15328007SEM0902_5</a></li>
<li>Drasgow, F., &amp; Kanfer, R. (1985). Equivalence of psychological measurement in heterogeneous populations. <em>Journal of Applied Psychology, 70</em>, 662-680. <a href="https://doi.org/10.1037//0021-9010.70.4.662">https://doi.org/10.1037//0021-9010.70.4.662</a></li>
<li>Eid, M. (2000). A multitrait–multimethod model with minimal assumptions. <em>Psychometrika, 65</em>, 241–261. <a href="https://doi.org/10.1007/BF02294377">https://doi.org/10.1007/BF02294377</a></li>
<li>Eid, M., Lischetzke, T., Nussbeck, F. W., &amp; Trierweiler, L. I. (2003). Separating trait effects from trait-specific method effects in multitrait-multimethod models: A multiple-indicator CT-C(M-1) model. <em>Psychological Methods, 8</em>, 38-60. <a href="https://doi.org/10.1037/1082-989X.8.1.38">https://doi.org/10.1037/1082-989X.8.1.38</a></li>
<li>Gallagher, A., Bridgeman, B., &amp; Cahalan, C. (2002). The effect of computer-based tests on racial-ethnic and gender groups. <em>Journal of Educational Measurement, 39</em>, 133-147. <a href="https://doi.org/10.1111/j.1745-3984.2002.tb01139.x">https://doi.org/10.1111/j.1745-3984.2002.tb01139.x</a></li>
<li>Gleser, L. J., &amp; Olkin, I. (1994). Stochastically dependent effect sizes. In H. M. Cooper, &amp; L. V. Hedges (Eds.), <em>The handbook of research synthesis</em> (pp. 339-355). New York: Sage.</li>
<li>Goldberg, A. L., &amp; Pedulla, J. J. (2002). Performance differences according to test mode and computer familiarity on a practice Graduate Record Exam. <em>Educational &amp; Psychological Measurement, 62</em>, 1053-1067. <a href="https://doi.org/10.1177/0013164402238092">https://doi.org/10.1177/0013164402238092</a></li>
<li>Horkay, N., Bennett, R. E., Allen, N., &amp; Kaplan, B. (2005). Online assessment in writing. In B. Sandene, N. Horkay, R. E. Bennett, N. Allen, J. Braswell, B. Kaplan, &amp; A. Oranje (Eds.), <em>Online assessment in mathematics and writing: Reports from the NAEP Technology-Based Assessment Project (NCES 2005-457)</em>. Washington, DC: U.S. Department of Education, National Center for Education Statistics.</li>
<li>Kim, J.-P. (1999). <em>Meta-analysis of equivalence of computerized and P&amp;P tests on ability measures.</em> Paper presented at the annual meeting of the Mid-Western Educational Research Association, Chigaco, IL.</li>
<li>Leeson, H. V. (2006). The mode effect: A literature review of human and technological issues in computerized testing. <em>International Journal of Testing, 6</em>, 1-24. <a href="https://doi.org/10.1207/s15327574ijt0601_1">https://doi.org/10.1207/s15327574ijt0601_1</a></li>
<li>Lubke, G. H., Dolan, C. V., Kelderman, H., &amp; Mellenbergh, G. J. (2003). On the relationship between sources of within- and between-group differences and measurement invariance in the common factor model. <em>Intelligence, 31</em>, 543-566. <a href="https://doi.org/10.1016/S0160-2896(03)00051-5">https://doi.org/10.1016/S0160-2896(03)00051-5</a></li>
<li>Marsh, H. W., &amp; Grayson, D. (1995). Latent Variable Models of Multitrait-Multimethod Data. In R. H. Hoyle (Ed.), <em>Structural Equation Modeling</em> (pp. 177-198). Thousand Oaks: Sage.</li>
<li>Mead, A. D., &amp; Drasgow, F. (1993). Equivalence of computerized and paper-and-pencil cognitive ability tests: A meta-analysis. <em>Psychological Bulletin, 114</em>, 449-458. <a href="https://doi.org/10.1037/0033-2909.114.3.449">https://doi.org/10.1037/0033-2909.114.3.449</a></li>
<li>Mellenbergh, G.J. (1982). Contingency table models for assessing item bias. <em>Journal of Eduactional Statistics, 7</em>, 105-118. <a href="https://doi.org/10.3102/10769986007002105">https://doi.org/10.3102/10769986007002105</a></li>
<li>Meredith, W. (1993). Measurement invariance, factor analysis and factorial invariance. <em>Psychometrika, 58</em>, 525-543. <a href="https://doi.org/10.1007/BF02294825">https://doi.org/10.1007/BF02294825</a></li>
<li>Millsap, R. E. (2005). Four Unresolved Problems in Studies of Factorial Invariance. In A. Maydeu-Olivares, &amp; J. J. McArdle (Eds.), <em>Multivariate applications book series. Contemporary psychometrics: A festschrift for Roderick P. McDonald</em> (pp. 153-171). Mahwah, NJ, US: Lawrence Erlbaum Associates Publishers.</li>
<li>Neuman, G., &amp; Baydoun, R. (1998). Computerization of paper-and-pencil tests: When are they equivalent? <em>Applied Psychological Measurement, 22</em>, 71-83. <a href="https://doi.org/10.1177/01466216980221006">https://doi.org/10.1177/01466216980221006</a></li>
<li>Overton, R. C., Taylor, L. R., Zickar, M. J., &amp; Harms, H. J. (1996). The pen-based computer as an alternative platform for test administration. <em>Personnel Psychology, 49</em>, 455-464. <a href="https://doi.org/10.1111/j.1744-6570.1996.tb01808.x">https://doi.org/10.1111/j.1744-6570.1996.tb01808.x</a></li>
<li>Wang, S., Jiao, H., Young, M. J., Brooks, T., &amp; Olson, J. (2007). A meta-analysis of testing mode effects in grade K-12 mathematics tests. <em>Educational and Psychological Measurement, 67</em>, 219-238. <a href="https://doi.org/10.1177/0013164406288166">https://doi.org/10.1177/0013164406288166</a></li>
<li>Wang, S., Jiao, H., Young, M. J., Brooks, T., &amp; Olson, J. (2008). Comparability of computer-based and paper-and-pencil testing in K 12 reading assessments: A meta-analysis of testing mode effects. <em>Educational and Psychological Measurement, 68</em>, 5-24. <a href="https://doi.org/10.1177/0013164407305592">https://doi.org/10.1177/0013164407305592</a></li>
<li>Wicherts, J. M. (2007). <em>Group differences in intelligence group performance</em>. Unpublished doctoral dissertation, University of Amsterdam, Amsterdam.</li>
<li>Widaman, K. F. (1985). Hierarchically nested covariance structure models for multitrait-multimethod data. <em>Applied Psychological Measurement, 10</em>, 1-26. <a href="https://doi.org/10.1177/014662168500900101">https://doi.org/10.1177/014662168500900101</a></li>
<li>Wilhelm, O. (2005). Measuring reasoning ability. In O. Wilhelm, &amp; R. W. Engle (Eds.), <em>Understanding and measuring intelligence</em> (pp. 373-392). London: Sage. <a href="https://doi.org/10.4135/9781452233529.n21">https://doi.org/10.4135/9781452233529.n21</a></li>
</ul>

        </p>
    </div>
    

    

    <div class="page-footer">
        
        <hr class="footer-divider">
        
            <a class="tag" href="/tags/cba">#CBA</a>
        
            <a class="tag" href="/tags/mgcfa">#MGCFA</a>
        
            <a class="tag" href="/tags/measurement-invariance">#measurement invariance</a>
        
      
    </div>


        


        </div>
        <footer class="footer-mobile">
	<div class="social-icons">
        
    <a class="social-icon" href="mailto:schroeders@psychologie.uni-kassel.de" target="_blank" rel="noopener" title="Email">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
            <path d="M25.2794292,5.59128519 L14,16.8707144 L2.72057081,5.59128519 C3.06733103,5.30237414 3.51336915,5.12857603 4,5.12857603 L24,5.12857603 C24.4866308,5.12857603 24.932669,5.30237414 25.2794292,5.59128519 Z M25.9956978,6.99633695 C25.998551,7.04004843 26,7.08414302 26,7.12857603 L26,20.871424 C26,21.0798433 25.9681197,21.2808166 25.9089697,21.4697335 L18.7156355,14.2763993 L25.9956978,6.99633695 Z M24.9498374,22.6319215 C24.6672737,22.7846939 24.3437653,22.871424 24,22.871424 L4,22.871424 C3.5268522,22.871424 3.09207889,22.7071233 2.74962118,22.432463 L10.0950247,15.0870594 L13.9848068,18.9768415 L14.1878486,18.7737996 L14.2030419,18.7889929 L17.6549753,15.3370594 L24.9498374,22.6319215 Z M2.00810114,21.0526627 C2.00273908,20.9929669 2,20.9325153 2,20.871424 L2,7.12857603 C2,7.08414302 2.00144896,7.04004843 2.00430222,6.99633695 L9.03436454,14.0263993 L2.00810114,21.0526627 Z"></path>
        </svg>
    </a>
    

    

    
    <a class="social-icon" href="https://twitter.com/Navajoc0d3" target="_blank" rel="noopener" title="Twitter">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
            <path d="M8.991284,24.971612 C19.180436,24.971612 24.752372,16.530224 24.752372,9.210524 C24.752372,8.970656 24.747512,8.731868 24.736496,8.494376 C25.818008,7.712564 26.758256,6.737 27.5,5.62622 C26.507372,6.067076 25.439252,6.364292 24.318752,6.498212 C25.462472,5.812628 26.340512,4.727444 26.754584,3.434036 C25.684088,4.068536 24.499004,4.53002 23.23724,4.778528 C22.226468,3.701876 20.786828,3.028388 19.193828,3.028388 C16.134404,3.028388 13.653536,5.509256 13.653536,8.567492 C13.653536,9.0023 13.702244,9.424904 13.797176,9.830552 C9.19346,9.599108 5.11106,7.39472 2.3792,4.04294 C1.903028,4.861364 1.629032,5.812628 1.629032,6.827072 C1.629032,8.74904 2.606972,10.445612 4.094024,11.438132 C3.185528,11.41016 2.331788,11.160464 1.585184,10.745096 C1.583888,10.768208 1.583888,10.791428 1.583888,10.815728 C1.583888,13.49888 3.493652,15.738584 6.028088,16.246508 C5.562932,16.373084 5.07326,16.44134 4.56782,16.44134 C4.210988,16.44134 3.863876,16.406024 3.526484,16.34144 C4.231724,18.542264 6.276596,20.143796 8.701412,20.18894 C6.805148,21.674696 4.416836,22.56008 1.821488,22.56008 C1.374476,22.56008 0.93362,22.534592 0.5,22.4834 C2.951708,24.054476 5.862524,24.971612 8.991284,24.971612"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    
    

    
    
    

    

    
    <a class="social-icon" href="xnKlUWIAAAAJ" target="_blank" rel="noopener" title="Google Scholar">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
             <path d="M15.7399177,5.48151786 C15.149924,4.82272859 14.4663239,4.49480724 13.6933878,4.49480724 C12.8185607,4.49480724 12.1471312,4.80966127 11.6791845,5.43796013 C11.2112379,6.06433732 10.9771365,6.82326666 10.9771365,7.71483354 C10.9771365,8.47423262 11.1052474,9.24733956 11.3616402,10.035649 C11.6170934,10.8236168 12.0350768,11.5270314 12.6210136,12.1470458 C13.2049434,12.7685974 13.8844439,13.0787968 14.6564833,13.0787968 C15.5171327,13.0787968 16.189459,12.7903763 16.671626,12.2137916 C17.1517432,11.6379755 17.3927199,10.9111166 17.3927199,10.035649 C17.3927199,9.29000051 17.2655484,8.50924961 17.0102233,7.69296927 C16.7561365,6.87562134 16.3319184,6.13812924 15.739875,5.48156056 L15.7399177,5.48151786 Z M24.3072528,4.96950105 L24.3072528,13.3462071 C24.3072528,13.7339989 23.9898792,14.0515006 23.6019592,14.0515006 L23.3422783,14.0515006 C22.9543156,14.0515006 22.6369848,13.7341271 22.6369848,13.3462071 L22.6369848,4.96950105 C22.6369848,4.62513879 22.5869788,4.33765779 23.068249,4.27714671 L23.068249,3.16262405 L19.3634081,6.20120253 C19.4061972,6.28058863 19.446851,6.33132057 19.4854124,6.39789556 C19.8110278,6.97418137 19.9768461,7.69087679 19.9768461,8.56681414 C19.9768461,9.23824368 19.8649625,9.84134739 19.638078,10.3740328 C19.4122611,10.9065473 19.1375912,11.3415267 18.817143,11.6765369 C18.496652,12.0127855 18.1752643,12.3201237 17.8538766,12.5967152 C17.5324462,12.8739047 17.2577763,13.162923 17.0328135,13.4629589 C16.8060571,13.7620125 16.6932767,14.0712297 16.6932767,14.3917206 C16.6932767,14.7126813 16.8397076,15.0387237 17.1317151,15.3673283 C17.4226551,15.6968724 17.7805972,16.0162103 18.2038758,16.3317049 C18.6279231,16.6450216 19.0510736,16.9928002 19.4743522,17.3712399 C19.8985703,17.74921 20.2545052,18.2354765 20.5454452,18.8259399 C20.8385631,19.4186239 20.9848231,20.071093 20.9848231,20.7882582 C20.9848231,21.7343577 20.7435475,22.5887297 20.2626616,23.3491963 C19.7802812,24.1064175 19.1518542,24.7106315 18.3796867,25.1537246 C17.6054695,25.599807 16.777531,25.9355858 15.8945476,26.1623422 C15.0097279,26.3870488 14.1317408,26.5 13.2548639,26.5 C12.7014246,26.5 12.1429889,26.4573818 11.5814359,26.3697112 C11.0178757,26.2822114 10.4532907,26.1276668 9.8847343,25.9098782 C9.31502485,25.6906377 8.81052389,25.4214338 8.37319577,25.0981672 C7.93475736,24.778146 7.58181166,24.3652016 7.3111559,23.862238 C7.04054285,23.3591036 6.90615445,22.7936645 6.90615445,22.1655364 C6.90615445,21.4203577 7.1136515,20.7291563 7.52975591,20.0847582 C7.94586031,19.4451002 8.49707907,18.9108775 9.18272893,18.487727 C10.3789864,17.7434877 12.2558547,17.2836547 14.8102164,17.1098936 C14.2262867,16.3799173 13.9333396,15.6928582 13.9333396,15.0498693 C13.9333396,14.6841125 14.0289531,14.2920503 14.218173,13.8687717 C13.9130554,13.9113899 13.5987992,13.9355175 13.2781801,13.9355175 C11.9059836,13.9355175 10.7472627,13.4894351 9.80628769,12.5911638 C8.86535538,11.6944724 8.39535897,10.5719642 8.39535897,9.21488479 C8.39535897,9.07298054 8.39941581,8.94802965 8.40970739,8.8095417 L2.83316537,8.8095417 L11.2417283,1.5 L25.1668346,1.5 L23.87996,2.50451805 L23.87996,4.27748834 C24.3577712,4.3388962 24.3072955,4.62607827 24.3072955,4.96950105 L24.3072528,4.96950105 Z M15.8172967,17.9839947 C15.6566455,17.9549562 15.430914,17.9386434 15.1399313,17.9386434 C14.512273,17.9386434 13.8947782,17.9941154 13.2885571,18.1048887 C12.6822934,18.2126727 12.084186,18.3947184 11.4941496,18.6515809 C10.9019353,18.906906 10.423996,19.2823566 10.0597766,19.7787865 C9.69355004,20.274576 9.51150436,20.858463 9.51150436,21.5303623 C9.51150436,22.1706609 9.67215551,22.7419077 9.99371402,23.2394479 C10.3142049,23.7338281 10.7373127,24.1208513 11.2632509,24.3980408 C11.7891891,24.6756999 12.3405787,24.8854176 12.916224,25.0231795 C13.4929795,25.1600875 14.0799412,25.2311463 14.6780913,25.2311463 C15.8610679,25.2311463 16.8794647,24.9647609 17.7338794,24.4320756 C18.5863724,23.899561 19.0135798,23.0772595 19.0135798,21.9672634 C19.0135798,21.7338025 18.9810823,21.5040141 18.916856,21.2796064 C18.8498112,21.0527219 18.7835352,20.8585057 18.7185829,20.6972567 C18.6534171,20.5389543 18.529363,20.3483679 18.3462498,20.1286576 C18.1642041,19.9083067 18.0248194,19.7455631 17.9310848,19.6372239 C17.8354714,19.5253403 17.6565431,19.3656714 17.3929761,19.1545445 C17.131587,18.9425209 16.9647012,18.8103104 16.8904822,18.7614574 C16.8172027,18.7100422 16.6270434,18.5711699 16.3207728,18.3458227 C16.0147157,18.1186393 15.8468903,17.9981723 15.8173394,17.983952 L15.8172967,17.9839947 Z"></path>
        </svg>
    </a>
    

    

    
    <a class="social-icon" href="https://orcid.org/0000-0002-5225-1122" target="_blank" rel="noopener" title="Orcid">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="https://www.w3.org/2000/svg" xmlns:xlink="https://www.w3.org/1999/xlink">
            <path d="M27,14 C27,21.1804687 21.1804687,27 14,27 C6.81953125,27 1,21.1804687 1,14 C1,6.81953125 6.81953125,1 14,1 C21.1804687,1 27,6.81953125 27,14 Z M9.76484375,19.9109375 L9.76484375,13.9492188 L9.76484375,9.03359375 L8.20078125,9.03359375 L8.20078125,19.9109375 L9.76484375,19.9109375 Z M12.0601563,9.03359375 L12.0601563,19.9210938 L16.3054688,19.9210938 C19.890625,19.9210938 22.0742188,17.2703125 22.0742188,14.4773437 C22.0742188,11.9078125 20.3070313,9.03359375 16.2851563,9.03359375 L12.0601563,9.03359375 Z M13.6242188,18.509375 L13.6242188,10.4453125 L16.03125,10.4453125 C19.078125,10.4453125 20.4695313,12.29375 20.4695313,14.4773437 C20.4695313,15.8179688 19.6570313,18.509375 16.1125,18.509375 L13.6242188,18.509375 Z M10.0085938,6.76875 C10.0085938,6.21015625 9.5515625,5.74296875 8.9828125,5.74296875 C8.4140625,5.74296875 7.95703125,6.2 7.95703125,6.76875 C7.95703125,7.32734375 8.4140625,7.79453125 8.9828125,7.79453125 C9.5515625,7.79453125 10.0085938,7.32734375 10.0085938,6.76875 Z"></path>
        </svg>
    </a>
    

    

</div>




	<div class="footer-mobile-links">
		<p><a href="https://github.com/kimcc/hugo-theme-noteworthy" target="_blank" rel="noopener">Noteworthy theme</a></p>
		<span class="divider-bar">|</span>
		<p><a href="https://gohugo.io" target="_blank" rel="noopener">Built with Hugo</a></p>
	</div>

	<script src="https://ulrich-schroeders.de/js/main.min.c1aee25a817e9beb1f9c4afd9d62311227a7f5e46720e404dc1dda97281f47f2.js" integrity="sha256-wa7iWoF+m+sfnEr9nWIxEien9eRnIOQE3B3alygfR/I=" crossorigin="anonymous"></script>
</footer>
    </body>
</html>